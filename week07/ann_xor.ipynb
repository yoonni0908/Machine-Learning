{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FdZnDI8azinw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665621831022,"user_tz":-540,"elapsed":24693,"user":{"displayName":"박상윤","userId":"15581713056968829844"}},"outputId":"7937a811-7eec-4148-99cc-aa094bbae5be"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"JBGiT1Qw_Qzo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665621912430,"user_tz":-540,"elapsed":636,"user":{"displayName":"박상윤","userId":"15581713056968829844"}},"outputId":"746fa283-056a-4db6-99a7-fcedbc393edc"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import accuracy_score\n","\n","# 데이터 읽기 함수\n","def load_dataset(file):\n","  data = np.loadtxt(file)\n","  print(\"DATA=\",data)\n","  \n","  input_features = data[:,0:-1] #맨뒤에 있는 행이 -1\n","  print(\"X=\",input_features)\n","  \n","  labels = np.reshape(data[:,-1],(4,1)) #행 형태로 바꿈 - 1행 4열로 바꿈\n","  print(\"Y=\",labels)\n"," \n","  input_features = torch.tensor(input_features, dtype=torch.float)\n","  labels = torch.tensor(labels, dtype=torch.float)\n","\n","  return (input_features, labels)\n","\n","# 모델 평가 결과 계산을 위해 텐서를 리스트로 변환하는 함수\n","def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()\n","\n","x, y = load_dataset(\"/gdrive/My Drive/colab/ann/xor1/train.txt\")\n","\n","# layer 1 가중치 초기화\n","# 이곳을 완성하세요.\n","w1 = torch.randn(2, 2, requires_grad=True) #2x2 matrix, random 정규분포, grandient를 이용해서 update\n","b1 = torch.randn(2, requires_grad=True)\n","\n","print(\"\\n[Init]\\nw1 = {0}\".format(tensor2list(w1)))\n","print(\"b1 = {0}\".format(tensor2list(b1)))\n","\n","# layer 2 가중치 초기화\n","# 이곳을 완성하세요.\n","w2 = torch.randn(2, 1, requires_grad=True)\n","b2 = torch.randn(1, requires_grad=True)\n","\n","print(\"w2 = {0}\".format(tensor2list(w2)))\n","print(\"b2 = {0}\\n\".format(tensor2list(b2)))\n","\n","# Activation 함수 설정\n","sigmoid = nn.Sigmoid() #1.0/(1.0 + e ...) -> 값이 너무 작아져서 underflow가 발생\n","\n","# 이진분류 크로스엔트로피 비용 함수 설정 \n","loss_func = torch.nn.BCELoss() #Binary Cross Entropy\n","\n","# 옵티마이저 함수 (역전파 알고리즘을 수행할 함수)\n","optimizer = torch.optim.SGD([w1,b1,w2,b2],lr=0.2) #SGD는 torch에 구현됨.- Stochastic Gradient Descent, learning rate를 0.2로 줌\n","\n","# 모델 학습\n","for epoch in range(1001):\n","\n","    # H(X) 계산: forward 연산\n","    # 이곳을 완성하세요.\n","    L2 = sigmoid(torch.add(torch.matmul(x, w1), b1)) #x * w1 + b1을 sigmoid에 집어넣음\n","    hx = sigmoid(torch.add(torch.matmul(L2, w2), b2)) # WL + b 에서 sigmoid -> y^-\n","\n"," #backpropagation - gradient update\n","    # 비용 계산\n","    cost = loss_func(hx, y)\n","    # 역전파 수행\n","    cost.backward()\n","    optimizer.step()\n","\n","    # 100 에폭마다 비용 출력 - cost가 0에 가까워지면 break\n","    if epoch % 100 == 0:\n","        print(epoch, cost.item()) \n","\n","print(\"\\n[Learned]\\nw1 = {0}\".format(tensor2list(w1)))\n","print(\"b1 = {0}\".format(tensor2list(b1)))\n","print(\"w2 = {0}\".format(tensor2list(w2)))\n","print(\"b2 = {0}\\n\".format(tensor2list(b2)))\n","\n","# 모델 평가\n","# H(X) 계산: forward 연산\n","# 이곳을 완성사에요.\n","L2 = sigmoid(torch.add(torch.matmul(x, w1), b1))\n","hx = sigmoid(torch.add(torch.matmul(L2, w2), b2))\n","\n","logits = (hx > 0.5).float()\n","predicts = tensor2list(logits)\n","golds = tensor2list(y)\n","\n","print(\"\\nPRED=\",predicts)\n","print(\"GOLD=\",golds)\n","print(\"Accuracy : {0:f}\".format(accuracy_score(golds, predicts)))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["DATA= [[0. 0. 0.]\n"," [0. 1. 1.]\n"," [1. 0. 1.]\n"," [1. 1. 0.]]\n","X= [[0. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 1.]]\n","Y= [[0.]\n"," [1.]\n"," [1.]\n"," [0.]]\n","\n","[Init]\n","w1 = [[-0.11948607861995697, -0.5161756873130798], [1.2274647951126099, 0.7439289689064026]]\n","b1 = [1.011786937713623, 2.042276620864868]\n","w2 = [[-0.7945892810821533], [1.3063344955444336]]\n","b2 = [1.034568428993225]\n","\n","0 0.9715384244918823\n","100 0.6784604787826538\n","200 0.5699792504310608\n","300 0.501580536365509\n","400 0.47861599922180176\n","500 0.5286930799484253\n","600 0.597124457359314\n","700 0.60075443983078\n","800 0.5352240800857544\n","900 0.4801490902900696\n","1000 0.4971943199634552\n","\n","[Learned]\n","w1 = [[-151.41317749023438, -43.772186279296875], [176.28810119628906, -59.59593963623047]]\n","b1 = [75.93206787109375, -105.58467102050781]\n","w2 = [[-143.8271026611328], [-73.28816223144531]]\n","b2 = [142.9437255859375]\n","\n","\n","PRED= [[0.0], [0.0], [1.0], [0.0]]\n","GOLD= [[0.0], [1.0], [1.0], [0.0]]\n","Accuracy : 0.750000\n"]}]}]}