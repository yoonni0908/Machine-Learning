{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwxKv7Np5qMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808f01e2-9fdf-42db-fa45-0a39720ff307"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY7_UjO06Emi"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import (DataLoader, TensorDataset)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#모델 설계\n",
        "class SpacingRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(SpacingRNN, self).__init__()\n",
        "\n",
        "        # 전체 음절 개수\n",
        "        self.eumjeol_vocab_size = config[\"eumjeol_vocab_size\"]\n",
        "\n",
        "        # 음절 임베딩 사이즈\n",
        "        self.embedding_size = config[\"embedding_size\"]\n",
        "\n",
        "        # RNN 히든 사이즈\n",
        "        self.hidden_size = config[\"hidden_size\"]\n",
        "\n",
        "        # 분류할 라벨의 개수\n",
        "        self.number_of_labels = config[\"number_of_labels\"]\n",
        "\n",
        "        # 임베딩층: 랜덤 초기화 후 fine-tuning\n",
        "        # 이곳을 채우세요.\n",
        "        self.embedding = nn.Embedding(num_embeddings=self.eumjeol_vocab_size, embedding_dim=self.embedding_size, padding_idx=0)\n",
        "\n",
        "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
        "\n",
        "        # RNN layer\n",
        "        # 이곳을 채우세요.\n",
        "        #self.bi_gru = nn.GRU(input_size=self.embedding_size, hidden_size=self.hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.bi_lstm = nn.LSTM(input_size=self.embedding_size, hidden_size=self.hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # fully_connected layer를 통하여 출력 크기를 number_of_labels에 맞춰줌\n",
        "        # 이곳을 채우세요.\n",
        "        #(batch_size, max_length, hidden_size*2)-> (batch_size, max_length, number_of_labels)\n",
        "        self.linear = nn.Linear(in_features=self.hidden_size * 2, out_features=self.number_of_labels) #곱하기 2는 양방향이기 때문(bidirectional)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (batch_size, max_length) -> (batch_size, max_length, embedding_size)\n",
        "        eumjeol_inputs = self.embedding(inputs) #idx -> embedding(maxlength만큼 있는것이 batch만큼 있음)\n",
        "\n",
        "        # hidden_outputs, hidden_states = self.bi_gru(eumjeol_inputs)\n",
        "        hidden_outputs, hidden_states = self.bi_lstm(eumjeol_inputs) #두개 output을 hidden_output위에 올림\n",
        "\n",
        "        # (batch_size, max_length, hidden_size*2)\n",
        "        hidden_outputs = self.dropout(hidden_outputs)\n",
        "\n",
        "        # (batch_size, max_length, hidden_size*2) -> (batch_size, max_length, number_of_labels)\n",
        "        hypothesis = self.linear(hidden_outputs)\n",
        "\n",
        "        return hypothesis"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unh9In2q6OQK"
      },
      "source": [
        "# 데이터를 읽어 리스트에 저장\n",
        "def read_datas(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf8\") as inFile:\n",
        "        lines = inFile.readlines()\n",
        "    datas = []\n",
        "    for line in lines:\n",
        "        # 입력 문장을 \\t으로 분리\n",
        "        pieces = line.strip().split(\"\\t\")\n",
        "        # 입력 문자열을 음절 단위로 분리\n",
        "        eumjeol_sequence, label_sequence = pieces[0].split(), pieces[1].split() #[0]이 input [1]이 label\n",
        "        datas.append((eumjeol_sequence, label_sequence))\n",
        "    return datas\n",
        "\n",
        "# 데이터를 읽고 각각의 딕셔너리 생성\n",
        "def read_vocab_data(eumjeol_vocab_data_path): #음절을 다 쪼갠다음에 unique sort\n",
        "    label2idx, idx2label = {\"<PAD>\":0, \"B\":1, \"I\":2}, {0:\"<PAD>\", 1:\"B\", 2:\"I\"}\n",
        "    eumjeol2idx, idx2eumjeol = {}, {}\n",
        "\n",
        "    with open(eumjeol_vocab_data_path, \"r\", encoding=\"utf8\") as inFile:\n",
        "        lines = inFile.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        eumjeol = line.strip()\n",
        "        eumjeol2idx[eumjeol] = len(eumjeol2idx) #eumjeol을 key로 함 0, 1, 2, ...\n",
        "        idx2eumjeol[eumjeol2idx[eumjeol]] = eumjeol\n",
        "\n",
        "    return eumjeol2idx, idx2eumjeol, label2idx, idx2label\n",
        "\n",
        "def load_dataset(config):\n",
        "    datas = read_datas(config[\"input_data\"])\n",
        "    eumjeol2idx, idx2eumjeol, label2idx, idx2label = read_vocab_data(config[\"eumjeol_vocab\"])\n",
        "\n",
        "    # 음절 데이터, 각 데이터의 실제 길이, 라벨 데이터를 담을 리스트\n",
        "    eumjeol_features, eumjeol_feature_lengths, label_features = [], [], []\n",
        "\n",
        "    for eumjeol_sequence, label_sequence in datas:\n",
        "        eumjeol_feature = [eumjeol2idx[eumjeol] for eumjeol in eumjeol_sequence] #음절을 feature화(숫자로 바꿈)\n",
        "        label_feature = [label2idx[label] for label in label_sequence]\n",
        "\n",
        "        # 음절 sequence의 실제 길이\n",
        "        eumjeol_feature_length = len(eumjeol_feature)\n",
        "\n",
        "        # 모든 입력 데이터를 고정된 길이로 맞춰주기 위한 padding 처리\n",
        "        # 이곳을 채우세요.\n",
        "        eumjeol_feature += [0] * (config[\"max_length\"] - eumjeol_feature_length)\n",
        "        label_feature += [0] * (config[\"max_length\"] - eumjeol_feature_length)\n",
        "\n",
        "        # 변환한 데이터를 각 리스트에 저장\n",
        "        eumjeol_features.append(eumjeol_feature)\n",
        "        eumjeol_feature_lengths.append(eumjeol_feature_length)\n",
        "        label_features.append(label_feature)\n",
        "\n",
        "    # 변환한 데이터를 Tensor 객체에 담아 반환\n",
        "    eumjeol_features = torch.tensor(eumjeol_features, dtype=torch.long)\n",
        "    eumjeol_feature_lengths = torch.tensor(eumjeol_feature_lengths, dtype=torch.long)\n",
        "    label_features = torch.tensor(label_features, dtype=torch.long)\n",
        "\n",
        "    return eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBfpm6Ts6Reg"
      },
      "source": [
        "def train(config):\n",
        "    # RNN 모델 객체 생성\n",
        "    model = SpacingRNN(config).cuda()\n",
        "\n",
        "    # 데이터 읽기\n",
        "    eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label = load_dataset(config)\n",
        "\n",
        "    # 학습 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
        "    train_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n",
        "    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n",
        "\n",
        "    # 크로스엔트로피 비용 함수, padding은 계산하지 않음\n",
        "    # 이곳을 채우세요.\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    \n",
        "\n",
        "    # 모델 학습을 위한 optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(config[\"epoch\"]):\n",
        "\n",
        "        model.train()\n",
        "        costs = []\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            # 역전파 단계를 실행하기 전에 변화도를 0으로 변경\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "\n",
        "            # 음절 데이터, 각 데이터의 실제 길이, 라벨 데이터\n",
        "            inputs, input_lengths, labels = batch[0], batch[1], batch[2]\n",
        "\n",
        "            # 모델 출력 결과 얻어오기\n",
        "            hypothesis = model(inputs)\n",
        "\n",
        "            # hypothesis : (batch_size, max_length, number_of_labels) -> (batch_size*max_length, number_of_labels)\n",
        "            # labels : (batch_size, max_length) -> (batch_size*max_length, )\n",
        "            # 이곳을 채우세요.\n",
        "            cost = loss_func(hypothesis.reshape(-1, len(label2idx)), labels.flatten()) \n",
        "            cost.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # batch 단위 cost 값 저장\n",
        "            costs.append(cost.data.item())\n",
        "\n",
        "        torch.save(model.state_dict(), os.path.join(output_dir, \"epoch_{0:d}.pt\".format(epoch + 1)))\n",
        "\n",
        "        # epoch 별로 평균 loss 값과 정확도 출력\n",
        "        print(\"Average cost : {}\".format(np.mean(costs)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-A9SurF6UgG"
      },
      "source": [
        "# 모델 출력 라벨 sequence와 정답 라벨 sequence를 기반으로\n",
        "# 모델 출력 문장과 정답 문장 출력\n",
        "def make_sentence(inputs, predicts, labels, idx2eumjeol, idx2label):\n",
        "\n",
        "    predict_sentence, correct_sentence = \"\", \"\"\n",
        "\n",
        "    for index in range(len(inputs)):\n",
        "        eumjeol = idx2eumjeol[inputs[index]]\n",
        "        correct_label = idx2label[labels[index]]\n",
        "        predict_label = idx2label[predicts[index]]\n",
        "\n",
        "        # 시작 음절인 경우 공백을 추가해줄 필요가 없음\n",
        "        if (index == 0):\n",
        "            predict_sentence += eumjeol\n",
        "            correct_sentence += eumjeol\n",
        "            continue\n",
        "\n",
        "        # \"B\" 태그인 경우 어절의 시작 음절이므로 앞에 공백을 추가\n",
        "        if (predict_label == \"B\"):\n",
        "            predict_sentence += \" \"\n",
        "        predict_sentence += eumjeol\n",
        "\n",
        "        # \"B\" 태그인 경우 어절의 시작 음절이므로 앞에 공백을 추가\n",
        "        if (correct_label == \"B\"):\n",
        "            correct_sentence += \" \"\n",
        "        correct_sentence += eumjeol\n",
        "\n",
        "    return predict_sentence, correct_sentence\n",
        "\n",
        "# 텐서를 리스트로 변환하는 함수\n",
        "def tensor2list(input_tensor):\n",
        "    return input_tensor.cpu().detach().numpy().tolist()\n",
        "\n",
        "def test(config):\n",
        "    # 데이터 읽기\n",
        "    eumjeol_features, eumjeol_feature_lengths, label_features, eumjeol2idx, idx2eumjeol, label2idx, idx2label = load_dataset(config)\n",
        "\n",
        "    # 평가 데이터를 batch 단위로 추출하기 위한 DataLoader 객체 생성\n",
        "    test_features = TensorDataset(eumjeol_features, eumjeol_feature_lengths, label_features)\n",
        "    test_dataloader = DataLoader(test_features, shuffle=False, batch_size=1)\n",
        "\n",
        "    # RNN 모델 객체 생성\n",
        "    model = SpacingRNN(config).cuda()\n",
        "    # 사전학습한 모델 파일로부터 가중치 불러옴\n",
        "    model.load_state_dict(torch.load(os.path.join(config[\"output_dir_path\"], config[\"model_name\"])))\n",
        "\n",
        "    # 모델의 출력 결과와 실제 정답값을 담을 리스트\n",
        "    total_hypothesis, total_labels = [], []\n",
        "\n",
        "    for step, batch in enumerate(test_dataloader):\n",
        "\n",
        "        model.eval()\n",
        "        batch = tuple(t.cuda() for t in batch)\n",
        "\n",
        "        # 음절 데이터, 각 데이터의 실제 길이, 라벨 데이터\n",
        "        inputs, input_lengths, labels = batch[0], batch[1], batch[2]\n",
        "\n",
        "        # 모델 평가\n",
        "        hypothesis = model(inputs)\n",
        "\n",
        "        # (batch_size, max_length, number_of_labels) -> (batch_size, max_length) -> 3차원 argmax\n",
        "        hypothesis = torch.argmax(hypothesis, dim=-1)\n",
        "\n",
        "        # batch_size가 1이기 때문\n",
        "        input_length = tensor2list(input_lengths[0])\n",
        "        input = tensor2list(inputs[0])[:input_length]\n",
        "        label = tensor2list(labels[0])[:input_length]\n",
        "        hypothesis = tensor2list(hypothesis[0])[:input_length]\n",
        "\n",
        "        # 출력 결과와 정답을 리스트에 저장\n",
        "        total_hypothesis += hypothesis\n",
        "        total_labels += label\n",
        "\n",
        "        if (step < 10):\n",
        "            # 정답과 모델 출력 비교\n",
        "            predict_sentence, correct_sentence = make_sentence(input, hypothesis, label, idx2eumjeol, idx2label)\n",
        "            print(\"정답 : \" + correct_sentence)\n",
        "            print(\"출력 : \" + predict_sentence)\n",
        "            print()\n",
        "\n",
        "    # 정확도 출력\n",
        "    print(\"Accuracy : {}\".format(accuracy_score(total_labels, total_hypothesis)))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj-JT2466U9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb173d1-0875-476f-9bc4-781584287bc8"
      },
      "source": [
        "if(__name__==\"__main__\"):\n",
        "    root_dir = \"/gdrive/My Drive/colab/rnn/spacing\"\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    config = {\"mode\": \"train\",\n",
        "              \"model_name\":\"epoch_{0:d}.pt\".format(5),\n",
        "              \"input_data\":os.path.join(root_dir, \"train.txt\"),\n",
        "              \"output_dir_path\":output_dir,\n",
        "              \"eumjeol_vocab\": os.path.join(root_dir, \"eumjeol_vocab.txt\"),\n",
        "              \"label_vocab\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
        "              \"eumjeol_vocab_size\": 2458,\n",
        "              \"embedding_size\": 100,\n",
        "              \"hidden_size\": 100,\n",
        "              \"max_length\": 920,\n",
        "              \"number_of_labels\": 3,\n",
        "              \"epoch\":5,\n",
        "              \"batch_size\":64,\n",
        "              \"dropout\":0.3\n",
        "              }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average cost : 0.19103014348900016\n",
            "Average cost : 0.018622796192670925\n",
            "Average cost : 0.015086996593052827\n",
            "Average cost : 0.011903455457355402\n",
            "Average cost : 0.009853343756374302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BA8wtxg6Y9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad36e8f3-9820-49e0-e199-6b2267eee6c6"
      },
      "source": [
        "if(__name__==\"__main__\"):\n",
        "    root_dir = \"/gdrive/My Drive/colab/rnn/spacing\"\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    config = {\"mode\": \"test\",\n",
        "              \"model_name\":\"epoch_{0:d}.pt\".format(5),\n",
        "              \"input_data\":os.path.join(root_dir, \"test.txt\"),\n",
        "              \"output_dir_path\":output_dir,\n",
        "              \"eumjeol_vocab\": os.path.join(root_dir, \"eumjeol_vocab.txt\"),\n",
        "              \"label_vocab\": os.path.join(root_dir, \"label_vocab.txt\"),\n",
        "              \"eumjeol_vocab_size\": 2458,\n",
        "              \"embedding_size\": 100,\n",
        "              \"hidden_size\": 100,\n",
        "              \"max_length\": 920,\n",
        "              \"number_of_labels\": 3,\n",
        "              \"epoch\":5,\n",
        "              \"batch_size\":64,\n",
        "              \"dropout\":0.3\n",
        "              }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정답 : 그러고 보니 경리는 윤보혜의 근황에 대해 아는 것이 없어보였다.\n",
            "출력 : 그러고 보니 경리는 윤보혜의 근황에 대해 아는 것이 없어보였다.\n",
            "\n",
            "정답 : 이제 7년 대환란이 눈앞에 닥쳐왔습니다.\n",
            "출력 : 이 제7년대환란 이 눈 앞에닥쳐왔습니다.\n",
            "\n",
            "정답 : 이 관찰자에게 장치(예를 들면 90의 경사각을 가진 두 거울)를 제공하여, 같은 시각에 A와 B 두 곳을 한꺼번에 관찰할 수 있게 한다.\n",
            "출력 : 이 관찰자에게 장치(예를 들면 90의 경사각을 가진 두 거울)를 제공하여, 같은 시각에 A와 B두 곳을 한 꺼번에 관찰할 수 있게 한다.\n",
            "\n",
            "정답 : \"먼저 약속을 어긴 쪽은 한달준 그 놈이었어.\"\n",
            "출력 : \" 먼저 약속을 어긴쪽은 한달준 그 놈이었어.\"\n",
            "\n",
            "정답 : 레이첼.\n",
            "출력 : 레이첼.\n",
            "\n",
            "정답 : 처남은 의사의 진단서를 북북 찢어버렸다.\n",
            "출력 : 처남은의사의 진단서를 북북찢어버렸다.\n",
            "\n",
            "정답 : 그 전화를 받았던 날, 과일을 벗기던 혜숙이가 물었었다.\n",
            "출력 : 그 전화를 받았던날, 과일을 벗기던 혜숙이가 물었었다.\n",
            "\n",
            "정답 : \"저도 처음에는 금변호사님처럼 그렇게 생각했지요. 그러나 범인은 경계선을 사이에 두고 한쪽 발은 테이블쪽에 두고 한쪽 발을 홀 중앙에 두고 있던 있던 게 분명해요.\"\n",
            "출력 : \"저도 처음에는 금변호사님처럼 그렇게 생각했지요. 그러나 범인은 경계선을 사이에 두고 한쪽발은 테이블 쪽에 두고 한 쪽발을 홀중앙에 두고 있던 있던게 분명해요.\"\n",
            "\n",
            "정답 : 1979년 <모두를 위한 정의>로 마지막 오스카 주연상 후보에 올랐었으나 이 영화를 제외하고는 70년대 말과 80년대 초를 통틀어 별로 신통한 영화에는 나오지 않았다.\n",
            "출력 : 1979년 <모두를 위한 정의 >로 마지 막오스카주연상후보에 올랐었으나이 영화를 제외하고는 70년 대말과 80년대초를 통틀어별로 신통한 영화에는 나오지 않았다.\n",
            "\n",
            "정답 : 경찰은 처음에 그 사건이 아그자 혼자 저지른 단독 범행인 줄 알았지만 조사 결과 두 명 이상의 공범이 있었음이 밝혀졌고, 수사가 진전됨에 따라 그 배후에는 여러 나라의 테러조직과 정보기관들이 난마처럼 얽혀 있음이 드러났다.\n",
            "출력 : 경찰은 처음에 그사건이 아 그자혼자저지른 단독범행인 줄 알았지만 조사결과 두명이상의 공범이 있었음이 밝혀졌고, 수사가 진전됨에 따라 그배후에는 여러나라의 테러 조직과 정보기관들이 난마처럼 얽혀 있음이 드러났다.\n",
            "\n",
            "Accuracy : 0.8929149142672275\n"
          ]
        }
      ]
    }
  ]
}