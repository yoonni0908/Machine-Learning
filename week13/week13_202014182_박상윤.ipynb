{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j65i49dU8Cjs",
        "outputId": "dc6e0832-0cd8-45b0-d7f0-6094720c314b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zVeC5Mf8C-S"
      },
      "source": [
        "from torch.utils.data import (DataLoader, TensorDataset)\n",
        "from torch import nn\n",
        "from tqdm import tqdm #space 바를 실행시켜주는 라이브러리 \n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "class TransformerChat(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # 전체 단어(음절) 개수\n",
        "        self.vocab_size = config[\"vocab_size\"]\n",
        "\n",
        "        # 단어(음절) 벡터 크기\n",
        "        self.embedding_size = config['embedding_size']\n",
        "\n",
        "        # Transformer의 Attention Head 개수\n",
        "        self.num_heads = config['num_heads']\n",
        "\n",
        "        # Transformer Encoder의 Layer 수\n",
        "        self.num_encoder_layers = config['num_encoder_layers']\n",
        "\n",
        "        # Transformer Decoder의 Layer 수\n",
        "        self.num_decoder_layers = config['num_decoder_layers']\n",
        "\n",
        "        # 입력 Sequence의 최대 길이\n",
        "        self.max_length = config['max_length']\n",
        "\n",
        "        # Transformer 내부 FNN 크기\n",
        "        self.hidden_size = config['hidden_size']\n",
        "\n",
        "        # Token Embedding Matrix 선언\n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.embedding_size)\n",
        "\n",
        "        # Transformer Encoder-Decoder 설계(선언)\n",
        "        self.transformer = nn.Transformer(d_model=self.embedding_size, nhead=self.num_heads, num_encoder_layers=self.num_encoder_layers,\n",
        "                                          num_decoder_layers=self.num_decoder_layers, dim_feedforward=self.hidden_size) #transformer에 parameter를 넣어줌\n",
        "       \n",
        "        # 입력 길이 L에 대한 (L X L) mask 생성: 이전 토큰들의 정보만을 반영하기 위한 mask\n",
        "        #       [[1, -inf, -inf, -inf],\n",
        "        #        [1,    1, -inf, -inf],\n",
        "        #               ......\n",
        "        #        [1,    1,    1,    1]]\n",
        "        # 이곳을 채우세요.\n",
        "        self.mask = self.transformer.generate_square_subsequent_mask(self.max_length).cuda()\n",
        "\n",
        "        # 전체 단어 분포로 변환하기 위한 linear\n",
        "        # 이곳을 채우세요.\n",
        "        self.projection_layer = nn.Linear(self.embedding_size,self.vocab_size) #맨 마지막에 decoding할 때\n",
        "\n",
        "    #모델 설계: forward\n",
        "    def forward(self, enc_inputs, dec_inputs): #encoder, decoder 두개 들어감 - seq2seq\n",
        "\n",
        "        # enc_inputs: [batch, seq_len], dec_inputs: [batch, seq_len]\n",
        "        # enc_input_features: [batch, seq_len, emb_size] -> [seq_len, batch, emb_size]\n",
        "        # 이곳을 채우세요.\n",
        "        enc_input_features = self.embeddings(enc_inputs).transpose(0, 1) #모양을 바꿈 0과 1을 바꿈 \n",
        "\n",
        "        # dec_input_features: [batch, seq_len, emb_size] -> [seq_len, batch, emb_size]\n",
        "        # 이곳을 채우세요.\n",
        "        dec_input_features = self.embeddings(dec_inputs).transpose(0, 1)\n",
        "\n",
        "        # dec_output_features: [seq_len, batch, emb_size]\n",
        "        dec_output_features = self.transformer(src=enc_input_features, tgt=dec_input_features, src_mask = self.mask, tgt_mask = self.mask)\n",
        "\n",
        "        # hypothesis : [seq_len, batch, vocab_size]\n",
        "        hypothesis = self.projection_layer(dec_output_features) #output 나온 것을 projection 시킴\n",
        "\n",
        "        return hypothesis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmYHzEcU8nRp"
      },
      "source": [
        "#사전 읽기\n",
        "# 어휘사전(vocabulary) 생성 함수\n",
        "def load_vocab(file_dir):\n",
        "\n",
        "    with open(file_dir,'r',encoding='utf-8') as vocab_file:\n",
        "        char2idx = {}\n",
        "        idx2char = {}\n",
        "        index = 0\n",
        "        for char in vocab_file:\n",
        "            char = char.strip()\n",
        "            char2idx[char] = index\n",
        "            idx2char[index] = char\n",
        "            index+=1\n",
        "\n",
        "    return char2idx, idx2char\n",
        "\n",
        "# 문자 입력열을 인덱스로 변환하는 함수\n",
        "def convert_data2feature(config, input_sequence, char2idx, decoder_input=False):\n",
        "\n",
        "    # 고정 길이 벡터 생성\n",
        "    input_features = np.zeros(config[\"max_length\"], dtype=np.int) #고정길이 세팅하고 나머지는 zero로 바꿈(pad 입력)\n",
        "\n",
        "    if decoder_input:\n",
        "        # Decoder Input은 Target Sequence에서 Right Shift\n",
        "        # Target Sequence :         [\"안\",\"녕\",\"하\",\"세\",\"요\", \"</S>\" ] #decoder의 output 형태\n",
        "        # Decoder Input Sequence :  [\"<S>\", \"안\",\"녕\",\"하\",\"세\",\"요\"] #decoder의 input 형태(한칸씩 밀려있음)\n",
        "        # 이곳을 채우세요.\n",
        "        input_sequence = \" \".join([\"<S>\"] + input_sequence.split()[:-1])\n",
        "\n",
        "    for idx,token in enumerate(input_sequence.split()):\n",
        "        if token in char2idx.keys():\n",
        "            input_features[idx] = char2idx[token]\n",
        "        else:\n",
        "            input_features[idx] = char2idx['<UNK>']\n",
        "\n",
        "    return input_features\n",
        "\n",
        "#데이터 로드\n",
        "# 데이터 읽기 함수\n",
        "def load_dataset(config):\n",
        "\n",
        "    # 어휘사전 읽어오기\n",
        "    char2idx, idx2char = load_vocab(config['vocab_file'])\n",
        "\n",
        "    file_dir = config['train_file']\n",
        "    data_file = open(file_dir,'r',encoding='cp949').readlines() # Q Vt A\n",
        "\n",
        "    # 데이터를 저장하기 위한 리스트 생성\n",
        "    enc_inputs, dec_inputs, dec_outputs = [], [], []\n",
        "\n",
        "    for line in tqdm(data_file):\n",
        "\n",
        "        line = line.strip().split('\\t') #line을 탭으로 분리\n",
        "\n",
        "        input_sequence = line[0]\n",
        "        output_sequence = line[1]\n",
        "\n",
        "        #모든 data를 읽어와서 붙여놓음, list를 다시 append함\n",
        "        enc_inputs.append(convert_data2feature(config, input_sequence, char2idx))\n",
        "        dec_inputs.append(convert_data2feature(config, output_sequence, char2idx, True)) #한칸씩 옆으로 함\n",
        "        dec_outputs.append(convert_data2feature(config, output_sequence, char2idx))\n",
        "\n",
        "    # 전체 데이터를 저장하고 있는 리스트를 텐서 형태로 변환\n",
        "    enc_inputs = torch.tensor(enc_inputs, dtype=torch.long)\n",
        "    dec_inputs = torch.tensor(dec_inputs, dtype=torch.long)\n",
        "    dec_outputs = torch.tensor(dec_outputs, dtype=torch.long)\n",
        "\n",
        "    return enc_inputs, dec_inputs, dec_outputs, char2idx, idx2char #사전 다시 return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ-bIKnw-1D8"
      },
      "source": [
        "# 텐서를 리스트로 변환하는 함수\n",
        "def tensor2list(input_tensor):\n",
        "    return input_tensor.cpu().detach().numpy().tolist()\n",
        "\n",
        "#평가\n",
        "def do_test(config, model, word2idx, idx2word, input_sequence=\"오늘 약속있으세요?\"):\n",
        "\n",
        "    # 평가 모드 셋팅\n",
        "    model.eval()\n",
        "\n",
        "    # 입력된 문자열의 음절을 공백 단위 토큰으로 변환. 공백은 <SP>로 변환: \"오늘 약속\" -> \"오 늘 <SP> 약 속\"\n",
        "    input_sequence = \" \".join([e if e != \" \" else \"<SP>\" for e in input_sequence])\n",
        "\n",
        "    # 텐서 변환: [1, seq_len]\n",
        "    enc_inputs = torch.tensor([convert_data2feature(config, input_sequence, word2idx)], dtype=torch.long).cuda()\n",
        "    \n",
        "    # input_ids : [1, seq_len] -> 첫번째 디코더 입력 \"<S>\" 만들기\n",
        "    dec_inputs = torch.tensor([convert_data2feature(config, \"\", word2idx, True)], dtype=torch.long).cuda() #한칸 옆으로 이동\n",
        "    \n",
        "    # 시스템 응답 문자열 초기화\n",
        "    response = ''\n",
        "\n",
        "    # 최대 입력 길이 만큼 Decoding Loop\n",
        "    for decoding_step in range(config['max_length']-1):\n",
        "\n",
        "        # dec_outputs: [vocab_size]\n",
        "        dec_outputs = model(enc_inputs, dec_inputs)[decoding_step, 0, :] #vocabulary 분포도로 나옴\n",
        "        # 가장 큰 출력을 갖는 인덱스 얻어오기\n",
        "        dec_output_idx = np.argmax(tensor2list(dec_outputs)) #list로 바꿈\n",
        "\n",
        "        # 생성된 토큰은 dec_inputs에 추가 (첫번째 차원은 배치)\n",
        "        dec_inputs[0][decoding_step+1] = dec_output_idx\n",
        "\n",
        "        # </S> 심볼 생성 시, Decoding 종료\n",
        "        if idx2word[dec_output_idx] == \"</S>\": #/S가 나오면 끝나는 것 - 이거 나올 때까지 생성함\n",
        "            break\n",
        "\n",
        "        # 생성 토큰 추가\n",
        "        response += idx2word[dec_output_idx]\n",
        "    \n",
        "    # <SP>를 공백으로 변환한 후 응답 문자열 출력\n",
        "    print(response.replace(\"<SP>\", \" \")) #공백은 <SP>로 나옴\n",
        "\n",
        "def test(config):\n",
        "\n",
        "    # 어휘사전 읽어오기\n",
        "    word2idx, idx2word = load_vocab(config['vocab_file'])\n",
        "\n",
        "    # Transformer Seq2Seq 모델 객체 생성\n",
        "    model = TransformerChat(config).cuda()\n",
        "\n",
        "    # 학습한 모델 파일로부터 가중치 불러옴\n",
        "    model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"trained_model_name\"])))\n",
        "\n",
        "    while(True):\n",
        "        input_sequence = input(\"문장을 입력하세요. (종료는 exit을 입력하세요.) : \")\n",
        "        if input_sequence == 'exit':\n",
        "            break\n",
        "        do_test(config, model, word2idx, idx2word, input_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow01KJjz-416"
      },
      "source": [
        "def train(config):\n",
        "\n",
        "    # Transformer Seq2Seq 모델 객체 생성\n",
        "    model = TransformerChat(config).cuda()\n",
        "\n",
        "    # 데이터 읽기\n",
        "    enc_inputs, dec_inputs, dec_outputs, word2idx, idx2word = load_dataset(config)\n",
        "\n",
        "    # TensorDataset/DataLoader를 통해 배치(batch) 단위로 데이터를 나누고 셔플(shuffle)\n",
        "    train_features = TensorDataset(enc_inputs, dec_inputs, dec_outputs)\n",
        "    train_dataloader = DataLoader(train_features, shuffle=True, batch_size=config[\"batch_size\"])\n",
        "\n",
        "    # 크로스엔트로피 손실 함수\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 옵티마이저 함수 지정\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learn_rate\"])\n",
        "\n",
        "    for epoch in range(config[\"epoch\"] + 1):\n",
        "\n",
        "        for (step, batch) in enumerate(train_dataloader):\n",
        "\n",
        "            # 학습 모드 셋팅\n",
        "            model.train()\n",
        "          \n",
        "            # batch = (enc_inputs[step], dec_inputs[step], dec_outputs)*batch_size\n",
        "            # .cuda()를 통해 메모리에 업로드\n",
        "            batch = tuple(t.cuda() for t in batch)\n",
        "\n",
        "            # 역전파 변화도 초기화\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            enc_inputs, dec_inputs, dec_outputs = batch\n",
        "\n",
        "            # hypothesis: [seq_len, batch, vocab_size] -> [seq_len*batch, vocab_size]\n",
        "            # 이곳을 채우세요. logits\n",
        "            hypothesis = model(enc_inputs, dec_inputs).view(-1, config[\"vocab_size\"]) #vocab size만큼 2차원으로 바꾸는 것\n",
        "\n",
        "            # labels: [batch, seq_len] -> [seq_len, batch] -> [seq_len(max_length)*batch]\n",
        "            labels = dec_outputs.transpose(0, 1) #1차원 형태로 늘림\n",
        "            labels = labels.reshape(config[\"max_length\"]*dec_inputs.size(0)) #배치 사이즈 바꿈\n",
        "\n",
        "            # 비용 계산 및 역전파 수행: cross_entopy 내부에서 labels를 원핫벡터로 변환 (골드레이블은 항상 1차원으로 입력)\n",
        "            loss = loss_func(hypothesis, labels) #hypotesis는 2차원 labels는 1차원 \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 200 배치마다 중간 결과 출력\n",
        "            if (step+1)% 200 == 0:\n",
        "                print(\"Current Step : {0:d} / {1:d}\\tCurrent Loss : {2:f}\".format(step+1, int(len(enc_inputs) / config['batch_size']), loss.item()))\n",
        "                # 생성 문장을 확인하기 위한 함수 호출\n",
        "                # do_test(config, model, word2idx, idx2word)\n",
        "\n",
        "        # 에폭마다 가중치 저장\n",
        "        torch.save(model.state_dict(), os.path.join(config[\"output_dir\"], \"epoch_{0:d}.pt\".format(epoch)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fk1BLZ-VrHe",
        "outputId": "8df46c66-2dfb-4564-8aae-31fb0e2c134b"
      },
      "source": [
        "if(__name__==\"__main__\"):\n",
        "\n",
        "    root_dir = \"/gdrive/My Drive/colab/transformer/chatbot/\"\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    config = {\"mode\": \"train\",\n",
        "              \"vocab_file\": os.path.join(root_dir, \"vocab.txt\"),\n",
        "              \"train_file\": os.path.join(root_dir, \"sampling_data4.txt\"),\n",
        "              \"trained_model_name\":\"epoch_{}.pt\".format(1),\n",
        "              \"output_dir\":output_dir,\n",
        "              \"epoch\": 5,\n",
        "              \"learn_rate\":0.00005,\n",
        "              \"num_encoder_layers\": 6,\n",
        "              \"num_decoder_layers\": 6,\n",
        "              \"num_heads\": 4,\n",
        "              \"max_length\": 100,\n",
        "              \"batch_size\": 128,\n",
        "              \"embedding_size\": 256,\n",
        "              \"hidden_size\": 512,\n",
        "              \"vocab_size\": 4427\n",
        "            }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1452 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "100%|██████████| 1452/1452 [00:00<00:00, 43351.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIhLXar0Ta-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff4183c-1f23-4c86-9a6a-1d9cdc67d720"
      },
      "source": [
        "if(__name__==\"__main__\"):\n",
        "\n",
        "    root_dir = \"/gdrive/My Drive/colab/transformer/chatbot/\"\n",
        "    output_dir = os.path.join(root_dir, \"output\")\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    config = {\"mode\": \"test\",\n",
        "              \"vocab_file\": os.path.join(root_dir, \"vocab.txt\"),\n",
        "              \"train_file\": os.path.join(root_dir, \"sampling_data4.txt\"),\n",
        "              \"trained_model_name\":\"epoch_{}.pt\".format(10),\n",
        "              \"output_dir\":output_dir,\n",
        "              \"epoch\": 1,\n",
        "              \"learn_rate\":0.00005,\n",
        "              \"num_encoder_layers\": 6,\n",
        "              \"num_decoder_layers\": 6,\n",
        "              \"num_heads\": 4,\n",
        "              \"max_length\": 20,\n",
        "              \"batch_size\": 128,\n",
        "              \"embedding_size\": 256,\n",
        "              \"hidden_size\": 512,\n",
        "              \"vocab_size\": 4427\n",
        "            }\n",
        "\n",
        "    if(config[\"mode\"] == \"train\"):\n",
        "        train(config)\n",
        "    else:\n",
        "        test(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 안녕\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 누구세요\n",
            "아니 그냥 그냥 그냥 사람 많이 하\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 뭐해\n",
            "나 지금 일하고있어\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : 수고해\n",
            "그래도 그렇지\n",
            "문장을 입력하세요. (종료는 exit을 입력하세요.) : exit\n"
          ]
        }
      ]
    }
  ]
}